## Impl√©mentation de trois m¬¥ethodes de Frequent Itemset Generation
### Introduction

Nous avons impl√©ment√© la phase Frequent Itemset Generation de l‚Äôalgorithme Apriori.
Trois m√©thodes de g√©n√©ration des candidats ont √©t√© test√©es :
- M√©thode 1 : Brute-force
- M√©thode 2 : F_{k-1} √ó F_1
- M√©thode 3 : F_{k-1} √ó F_{k-1}
Chaque itemset produit par notre fonction est annot√© :
- F : itemset fr√©quent
- I : itemset infrequent (apr√®s calcul du support)
- N : itemset √©limin√© directement par le principe Apriori
Nous pr√©sentons les r√©sultats obtenus pour les jeux de donn√©es (a) et (b), suivis d‚Äôune comparaison simple entre les trois m√©thodes.

### R√©sultats pour le dataset (a)

Transactions :
[["a","b","d","e"], ["b","c","d"], ...]
minsup = 0.3

##### M√©thode Brute-force

[Ins√©rer image 1 ici : sortie brute-force du dataset (a)]
üëâ Mettre ici ta capture contenant : 1-itemsets, 2-itemsets, 3-itemsets.

##### M√©thode F_{k-1} √ó F_1

[Ins√©rer image 2 ici : sortie fk1_f1 du dataset (a)]

##### M√©thode F_{k-1} √ó F_{k-1}

[Ins√©rer image 3 ici : sortie fk1_fk1 du dataset (a)]

### R√©sultats pour le dataset (b)

Transactions :
[["b","c","d"], ["a","b","c","d","e"], ...]
minsup = 0.5

##### M√©thode Brute-force

[Ins√©rer image 4 ici : sortie brute-force du dataset (b)]

##### M√©thode F_{k-1} √ó F_1

[Ins√©rer image 5 ici : sortie fk1_f1 du dataset (b)]

##### M√©thode F_{k-1} √ó F_{k-1}

[Ins√©rer image 6 ici : sortie fk1_fk1 du dataset (b)]

### Discussion
##### Nombre de candidats
La m√©thode Brute-force g√©n√®re tous les k-combinaisons possibles : beaucoup d‚Äôitemsets inutiles, plus de sorties annot√©es N ou I.
La m√©thode F_{k-1} √ó F_1 r√©duit le nombre de candidats mais reste imparfaite : elle g√©n√®re encore des combinaisons non valides.
La m√©thode F_{k-1} √ó F_{k-1} est la plus efficace : moins de candidats, moins d‚Äô√©l√©ments ‚ÄúN‚Äù, exploration plus cibl√©e.

##### Influence des datasets
Dans le dataset (a), les items apparaissent souvent ensemble ‚Üí plus d‚Äôitemsets fr√©quents ‚Üí grosses diff√©rences entre les m√©thodes.
Dans le dataset (b), le seuil minsup = 0.5 filtre davantage ‚Üí peu d‚Äôitemsets fr√©quents ‚Üí les trois m√©thodes convergent plus vite.

##### Conclusion simple
Brute-force : correcte mais inefficace.
F_{k-1} √ó F_1 : mieux, mais encore des candidats inutiles.
F_{k-1} √ó F_{k-1} : meilleure strat√©gie, proche de la version classique d‚ÄôApriori.

### Conclusion
Nous avons compar√© trois strat√©gies de g√©n√©ration d‚Äôitemsets dans Apriori. Les r√©sultats montrent clairement que la m√©thode F_{k-1} √ó F_{k-1} produit moins de candidats et √©vite les combinaisons impossibles gr√¢ce au principe d‚Äô√©lagage. C‚Äôest celle qui fonctionne le mieux dans les deux jeux de donn√©es.